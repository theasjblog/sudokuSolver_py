{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images must be of the same size. \n",
    "Resize all training images to the same size and convert to grayscale.\n",
    "\n",
    "Ideally I would like to try CNN and keras, but my machine cannot run tensorflow>=2.2, so I'll use \"more traditional\" ML approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import filters\n",
    "\n",
    "def imgProcessing(img):\n",
    "    img = cv2.resize(img, (30,30), interpolation = cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    img = filters.gaussian(img, sigma=1, multichannel=False)\n",
    "    img = filters.sobel(img)\n",
    "    return(img)\n",
    "\n",
    "def getLabelFromN(labels, n):\n",
    "    row = n//9\n",
    "    col = n-row*9\n",
    "    labels = labels[row][col]\n",
    "    return(labels)\n",
    "\n",
    "dataDir = './allForTraining/'\n",
    "labelDir = 'D:\\\\repos\\\\sudokuSolver_py\\\\rawImg\\\\'\n",
    "allFiles = os.listdir(dataDir)\n",
    "X = []\n",
    "y = []\n",
    "for i in allFiles:\n",
    "    img = cv2.imread(dataDir+i)\n",
    "    img = imgProcessing(img)\n",
    "    img = img/255\n",
    "    X.append(np.ndarray.flatten(img))\n",
    "    names = i.split('_')\n",
    "    imgName = names[0].split('.')[0]\n",
    "    imgNum = int(names[1].split('.')[0])\n",
    "    with open(labelDir+imgName+'.dat') as f:\n",
    "        labels = [line.split()[0:9] for line in f]\n",
    "    labels = labels[2:]\n",
    "    thisLabel = getLabelFromN(labels, imgNum)\n",
    "    y.append(thisLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check labels distribution\n",
    "from collections import Counter\n",
    "import pandas  as pd\n",
    "c = Counter(y)\n",
    "df = pd.DataFrame.from_dict(c, orient='index').reset_index()\n",
    "df['percentage'] = 100*df[0]/sum(df[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly equally distribute, except for a lot of 0s. We'll see if we need to take this into account for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('Train size: {}'.format(len(y_train)))\n",
    "print('Test size: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(clf, x_train, y_train, x_test, y_test, modelName):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    ac = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('{} accuracy: {}'.format(modelName, ac))\n",
    "    print(cm)\n",
    "    for i in range(0,len(cm)):\n",
    "        print(cm[i][i]*100/sum(cm[i]))\n",
    "    print(60*'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i tried a few k, accuracy is always pretty much the same\n",
    "clf = KNeighborsClassifier(5)\n",
    "do_fit(clf, x_train, y_train, x_test, y_test, 'K-Neighbors')\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0, max_depth=10)\n",
    "do_fit(clf, x_train, y_train, x_test, y_test, 'Decision Tree')\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1, max_depth=10, n_estimators=100)\n",
    "do_fit(clf, x_train, y_train, x_test, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1, max_depth=10, n_estimators=100)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "file = open('sudoku_clf.kb', 'wb')\n",
    "pickle.dump(clf, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
